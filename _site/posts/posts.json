[
  {
    "path": "posts/welcome/",
    "title": "Welcome to Visual Analytics Assignment",
    "description": "Welcome to our new blog, Visual Analytics Assignment. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-07-28",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-07-28T12:47:31+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-28-visual-analytics-assignment-part-1/",
    "title": "Visual Analytics Assignment Part 1",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Ong Chee Hong",
        "url": "https://www.linkedin.com/in/alexongch/"
      }
    ],
    "date": "2021-07-28",
    "categories": [],
    "contents": "\r\nVast Challenge 2021: Mini-Challenge 2\r\nBackground\r\nMany of the Abila, Kronos-based employees of GAStech have company cars which are approved for both personal and business use. Those who do not have company cars have the ability to check out company trucks for business use, but these trucks cannot be used for personal business.\r\nEmployees with company cars are happy to have these vehicles, because the company cars are generally much higher quality than the cars they would be able to afford otherwise. However, GAStech does not trust their employees. Without the employees? knowledge, GAStech has installed geospatial tracking software in the company vehicles. The vehicles are tracked periodically as long as they are moving.\r\nThis vehicle tracking data has been made available to law enforcement to support their investigation. Unfortunately, data is not available for the day the GAStech employees went missing. Data is only available for the two weeks prior to the disappearance.\r\nTo promote local businesses, Kronos based companies provide a Kronos Kares benefit card to GASTech employees giving them discounts and rewards in exchange for collecting information about their credit card purchases and preferences as recorded on loyalty cards. This data has been made available to investigators in the hopes that it can help resolve the situation. However, Kronos Kares does not collect personal information beyond purchases.\r\nAs a visual analytics expert assisting law enforcement, your mission is to identify which GASTech employees made which purchases and identify suspicious patterns of behavior. You must cope with uncertainties that result from missing, conflicting, and imperfect data to make recommendations for further investigation.\r\nQuestions\r\nUsing just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies? Please limit your answer to 8 images and 300 words.\r\nAdd the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find? Please limit your answer to 8 images and 500 words.\r\nCan you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data? Please limit your answer to 8 images and 500 words.\r\nGiven the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships. Please limit your response to 8 images and 500 words.\r\nDo you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why Please limit your response to 10 images and 500 words.\r\n#Scope of work\r\nTo address the questions above, below is the required scope of work 1. Literature Review 2. Data preparation 3. Methodology and visualisation 4. Answers 5. Acknowledgment\r\n1. Literature Review\r\nThis year Vast Challenge uses the same question based on 2014 Vast Challenge. As such, we will conduct literature review on past 2014 Vast Challenge submission based on MC2 – Patterns of Life Analysis. We will select some of the past submission to identify some of the gaps that can potentially utilized interactive data visualization techniques to improve user experiences. The repository for 2014 Vast Challenge – MC2: Patterns of Life Analysis submissions can be found here\r\n1.1 University of Buenos Aries - Arcaya.\r\nThe localization of different people based on bar chart is difficult to visualize as there are too many people with indicated by different type of colours and there are too many locations thereby squeezing the bar chart altogether. A recommendation is to split location up into 3-4 groups so that it will be easier to visualize.\r\n\r\n1.2 Shandong University\r\nThe price vs consumption area by using density plot is not a very good idea as it is very confusing to know which employee is which as there are too many employees squeeze into one chart. There is no legend or tooltip to indicate the employees.\r\n\r\n1.3. ASTRI\r\nThe bar chart used to indicate less frequented location is too squeezy especially those portion with many departments squeeze into one location. These makes it difficult for people to analyse. A recommendation is to group the data into lesser locations and possibly provided some interactivity where user can click the legend to select the department they want.\r\n\r\n2. Data preparation\r\n2.1 Customisation of code chunks\r\nFirst, we will customize the all code chunks using the below knitr code. More information on chunk options can be found here\r\n2.2 Installing required R packages\r\nNext, we will install the required R packages. There are three basic groups of packages that we will install,\r\nFor data manipulation and preparation The tidyverse package is a group of R packages including dplyr, tidyr that assist user to manipulate data.\r\nDate and Time The two packages clock and lubridate are used for the manipulation of date and time data\r\nInteractive data analysis The two packages ggiraph and plotly are used to output data into interactive graphical/chart form for analysis.\r\nGeoVisual Analysis The packages raster, sf,tmap and rgdal are used for geospatial visual analytics where data are output to a map for analysis such as movement of people etc.\r\nNetwork Analysis Lastly, to analyse the relationship between people etc. We will use the packages from tidygraph, igraph, ggraph and visNetwork. visNetwork is a package to output interactive network analysis.\r\n\r\n\r\npackages = c('DT','ggiraph','plotly','tidyverse', 'raster','sf','clock','tmap',\r\n             'rgdal','dplyr', 'tidyr', 'textclean', \"plotly\", \"forcats\", \"jpeg\", \"tiff\",\r\n             \"mapview\",\"tidygraph\",\"igraph\",\"ggraph\",\"visNetwork\",\"lubridate\")\r\nfor(p in packages){\r\n  if(!require(p,character.only = T)){\r\n    install.packages(p)\r\n  }\r\n  library(p,character.only = T)\r\n}\r\n\r\n\r\n\r\n2.3 Provided data and information\r\nThere are 3 different types of data & information provided. A geospatial dataset, csv files and a jpg file consisting of the Abila tourist map.\r\nBelow is the information of all the data provided.\r\n2.3.1. A csv file on vehicle assignments to employee (car-assignments.csv)\r\nEmployee Last Name\r\nEmployee First Name\r\nCar ID (integer)\r\nCurrent Employment Type (Department; categorical)\r\nCurrent Employment Title (job title; categorical)\r\n2.3.2. A CSV file of vehicle tracking data (gps.csv)\r\n3.1 Timestamp\r\n3.2 Car ID (integer)\r\n3.3 Latitude\r\n3.4 Longitude\r\n2.3.3. A CSV file containing loyalty card transaction data (loyalty_data.csv)\r\n4.1 Timestamp\r\n4.2 Location (name of the business)\r\n4.3 Price (real)\r\n4.4 Loyalty Number (A 5-character code starting with L that is unique for each card)\r\n2.3.4. A CSV file containing credit and debit card transaction data (cc_data.csv)\r\n5.1 Timestamp\r\n5.2 Location (name of the business)\r\n5.3 Price (real)\r\n5.4 Last 4 digits of the credit or debit card number\r\n2.3.5. ESRI shapefiles of Abila (in the Geospatial folder)\r\n2.3.6. A tourist map of Abila with locations of interest identified, in JPEG format (MC2-Tourist.jpg)\r\n2.4. Importing of data\r\nWe will import the 4 different csv datasets that were provided\r\n\r\n\r\ncar <- read_csv(\"data/mc2/car-assignments.csv\")\r\ncc <- read_csv(\"data/mc2/cc_data.csv\")\r\ngps <- read_csv(\"data/mc2/gps.csv\")\r\nloyalty <- read_csv(\"data/mc2/loyalty_data.csv\")\r\n\r\n\r\n\r\nIf we take a look at the above datasets in excel, we will see that there are foreign characters in some of the datasets provided. An example is the Katerina’s Cafe as shown below. To address this, we will need to encode the dataset to allow rstudio to read properly.\r\n\r\nTo allow use to know the encoding type for both cc and loyalty dataset. Guess encoding will be used to detect the encoding type as shown below..\r\n\r\n\r\nguess_encoding(cc)\r\n\r\n\r\n# A tibble: 1 x 2\r\n  encoding confidence\r\n  <chr>         <dbl>\r\n1 ASCII             1\r\n\r\nguess_encoding(loyalty)\r\n\r\n\r\n# A tibble: 1 x 2\r\n  encoding confidence\r\n  <chr>         <dbl>\r\n1 ASCII             1\r\n\r\nNext, we will add the code locale = locale(encoding = “ASCII” on both cc and loyalty dataset)\r\n\r\n\r\ncar <- read_csv(\"data/mc2/car-assignments.csv\")\r\ncc <- read_csv(\"data/mc2/cc_data.csv\", locale = locale(encoding = \"ASCII\"))\r\ngps <- read_csv(\"data/mc2/gps.csv\")\r\nloyalty <- read_csv(\"data/mc2/loyalty_data.csv\",locale = locale(encoding = \"ASCII\"))\r\n\r\n\r\n\r\n2.5. Data examination\r\nFirst, we will look at both cc and loyalty card dataset by using the glimpse function as shown below. There are 1490 rows and 1392 rows in both the cc and loyatly dataset respectfully. If we take look closely, we will see that these two datasets are closely linked by location, price and timestamp except the last4ccnum and loyaltynum are different.\r\nIf we take a look back at the MC2 background, we will observe that Kronos based companies are allowed to collect credit card and loyalty cards information on GAStech employees purchases as such these two datasets are similar in nature.\r\nHowever, the rows for both cc and loyalty card data are different. This anomaly might have a few reasoning, 1) the employees did not used their credit cards while doing purchases but loyalty card was presented. 2) Vice versa, employees might also used their credit card but did not present their loyalty card during purchases.\r\n\r\n\r\nglimpse(cc)\r\n\r\n\r\nRows: 1,490\r\nColumns: 4\r\n$ timestamp  <chr> \"1/6/2014 7:28\", \"1/6/2014 7:34\", \"1/6/2014 7:35\"~\r\n$ location   <chr> \"Brew've Been Served\", \"Hallowed Grounds\", \"Brew'~\r\n$ price      <dbl> 11.34, 52.22, 8.33, 16.72, 4.24, 4.17, 28.73, 9.6~\r\n$ last4ccnum <dbl> 4795, 7108, 6816, 9617, 7384, 5368, 7253, 4948, 9~\r\n\r\nglimpse(loyalty)\r\n\r\n\r\nRows: 1,392\r\nColumns: 4\r\n$ timestamp  <chr> \"1/6/2014\", \"1/6/2014\", \"1/6/2014\", \"1/6/2014\", \"~\r\n$ location   <chr> \"Brew've Been Served\", \"Brew've Been Served\", \"Ha~\r\n$ price      <dbl> 4.17, 9.60, 16.53, 11.51, 12.93, 4.27, 11.20, 15.~\r\n$ loyaltynum <chr> \"L2247\", \"L9406\", \"L8328\", \"L6417\", \"L1107\", \"L40~\r\n\r\nNext, we will look at the vehicle datasets. The 44 rows car datasets are represented by the employee, employment information with their car assignment ID.\r\nThe gps datasets are based on the car movements in respect to their lat and long position with timestamp.\r\n\r\n\r\nglimpse(car)\r\n\r\n\r\nRows: 44\r\nColumns: 5\r\n$ LastName               <chr> \"Calixto\", \"Azada\", \"Balas\", \"Barranc~\r\n$ FirstName              <chr> \"Nils\", \"Lars\", \"Felix\", \"Ingrid\", \"I~\r\n$ CarID                  <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12~\r\n$ CurrentEmploymentType  <chr> \"Information Technology\", \"Engineerin~\r\n$ CurrentEmploymentTitle <chr> \"IT Helpdesk\", \"Engineer\", \"Engineer\"~\r\n\r\nglimpse(gps)\r\n\r\n\r\nRows: 685,169\r\nColumns: 4\r\n$ Timestamp <chr> \"1/6/2014 6:28\", \"1/6/2014 6:28\", \"1/6/2014 6:28\",~\r\n$ id        <dbl> 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35~\r\n$ lat       <dbl> 36.07623, 36.07622, 36.07621, 36.07622, 36.07621, ~\r\n$ long      <dbl> 24.87469, 24.87460, 24.87444, 24.87425, 24.87417, ~\r\n\r\n2.6. Data Preparation\r\n2.6.1 CC and Loyalty dataset\r\nWe will prepare the cc and loyalty datasets for data exploration later.\r\n2.6.1.1. Changing the datatypes of last4ccnum & loyaltynum\r\nThe last4ccnum of the cc datasets and the loyaltynum of the loyalty dataset should be a categorical data type. As such, we will change it by using the as.factor function.\r\n\r\n\r\ncc$last4ccnum <- as.factor(cc$last4ccnum)\r\nloyalty$loyaltynum <- as.factor(loyalty$loyaltynum)\r\n\r\n\r\n\r\nNext, we will modify the datatype for both the timestamp of cc and loyalty dataset using the clock package. If we observe below, the data_time_parse function is use to change the timestamp to dttm (datetime) format while the date_parse function is used to change the data to date format.\r\n\r\n\r\ncc$timestamp <- date_time_parse(cc$timestamp,\r\n                                 zone = \"\",\r\n                                 format = \"%m/%d/%Y %H:%M\")\r\n\r\nloyalty$timestamp <- date_parse(loyalty$timestamp,\r\n                                 format = \"%m/%d/%Y\")\r\n\r\n\r\n\r\nWe will double check the dataset to confirm that the datatype has been changed to the one we wanted.\r\n\r\n\r\nglimpse(cc)\r\n\r\n\r\nRows: 1,490\r\nColumns: 4\r\n$ timestamp  <dttm> 2014-01-06 07:28:00, 2014-01-06 07:34:00, 2014-0~\r\n$ location   <chr> \"Brew've Been Served\", \"Hallowed Grounds\", \"Brew'~\r\n$ price      <dbl> 11.34, 52.22, 8.33, 16.72, 4.24, 4.17, 28.73, 9.6~\r\n$ last4ccnum <fct> 4795, 7108, 6816, 9617, 7384, 5368, 7253, 4948, 9~\r\n\r\nglimpse(loyalty)\r\n\r\n\r\nRows: 1,392\r\nColumns: 4\r\n$ timestamp  <date> 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, ~\r\n$ location   <chr> \"Brew've Been Served\", \"Brew've Been Served\", \"Ha~\r\n$ price      <dbl> 4.17, 9.60, 16.53, 11.51, 12.93, 4.27, 11.20, 15.~\r\n$ loyaltynum <fct> L2247, L9406, L8328, L6417, L1107, L4034, L6110, ~\r\n\r\n2.6.1.2 Splitting the timestamp data into individual date, time and day columns.\r\nTo allow us to dive deeper into our analysis later, we will split the timestamp dataset into date, time and day columns. We will first add more columns by using the mutate function from dplyr to add day, date and time columns in the cc dataset and importing in to the cc_dtsplit object.\r\nThere is no need to add columns for the loyatly dataset as we will join both the datasets together in which day will be included in the joined dataset.\r\n\r\n\r\ncc_dtsplit <- cc %>%\r\n  mutate(day = date_weekday_factor(cc$timestamp), date =  as_date(cc$timestamp), time = format(cc$timestamp, format = \"%H:%M\"))\r\n\r\ncc_dtsplit\r\n\r\n\r\n# A tibble: 1,490 x 7\r\n   timestamp           location      price last4ccnum day   date      \r\n   <dttm>              <chr>         <dbl> <fct>      <ord> <date>    \r\n 1 2014-01-06 07:28:00 Brew've Been~ 11.3  4795       Mon   2014-01-06\r\n 2 2014-01-06 07:34:00 Hallowed Gro~ 52.2  7108       Mon   2014-01-06\r\n 3 2014-01-06 07:35:00 Brew've Been~  8.33 6816       Mon   2014-01-06\r\n 4 2014-01-06 07:36:00 Hallowed Gro~ 16.7  9617       Mon   2014-01-06\r\n 5 2014-01-06 07:37:00 Brew've Been~  4.24 7384       Mon   2014-01-06\r\n 6 2014-01-06 07:38:00 Brew've Been~  4.17 5368       Mon   2014-01-06\r\n 7 2014-01-06 07:42:00 Coffee Camel~ 28.7  7253       Mon   2014-01-06\r\n 8 2014-01-06 07:43:00 Brew've Been~  9.6  4948       Mon   2014-01-06\r\n 9 2014-01-06 07:43:00 Brew've Been~ 16.9  9683       Mon   2014-01-06\r\n10 2014-01-06 07:47:00 Hallowed Gro~ 16.5  8129       Mon   2014-01-06\r\n# ... with 1,480 more rows, and 1 more variable: time <chr>\r\n\r\nTo allow us to join both datasets together, we will need to rename the timestamp column from the loyatly dataset to date so that both the date columns have the same name.\r\n\r\n\r\nloyalty_dt <- rename(loyalty, date = timestamp)\r\n\r\n\r\n\r\nWe will take a look at our newly cleaned datasets to double check the changed we have made previously.\r\n\r\n\r\nglimpse(cc_dtsplit)\r\n\r\n\r\nRows: 1,490\r\nColumns: 7\r\n$ timestamp  <dttm> 2014-01-06 07:28:00, 2014-01-06 07:34:00, 2014-0~\r\n$ location   <chr> \"Brew've Been Served\", \"Hallowed Grounds\", \"Brew'~\r\n$ price      <dbl> 11.34, 52.22, 8.33, 16.72, 4.24, 4.17, 28.73, 9.6~\r\n$ last4ccnum <fct> 4795, 7108, 6816, 9617, 7384, 5368, 7253, 4948, 9~\r\n$ day        <ord> Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon, Mon,~\r\n$ date       <date> 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, ~\r\n$ time       <chr> \"07:28\", \"07:34\", \"07:35\", \"07:36\", \"07:37\", \"07:~\r\n\r\nglimpse(loyalty_dt)\r\n\r\n\r\nRows: 1,392\r\nColumns: 4\r\n$ date       <date> 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, ~\r\n$ location   <chr> \"Brew've Been Served\", \"Brew've Been Served\", \"Ha~\r\n$ price      <dbl> 4.17, 9.60, 16.53, 11.51, 12.93, 4.27, 11.20, 15.~\r\n$ loyaltynum <fct> L2247, L9406, L8328, L6417, L1107, L4034, L6110, ~\r\n\r\n2.6.1.3. Changing the datatypes of car & gps\r\nFirst, we will take a look at the car & gps datasets. Notice that the CarID and id for both datasets are not of the correct categorical datatype. We will proceed to change both the two columns.\r\n\r\n\r\nglimpse(car)\r\n\r\n\r\nRows: 44\r\nColumns: 5\r\n$ LastName               <chr> \"Calixto\", \"Azada\", \"Balas\", \"Barranc~\r\n$ FirstName              <chr> \"Nils\", \"Lars\", \"Felix\", \"Ingrid\", \"I~\r\n$ CarID                  <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12~\r\n$ CurrentEmploymentType  <chr> \"Information Technology\", \"Engineerin~\r\n$ CurrentEmploymentTitle <chr> \"IT Helpdesk\", \"Engineer\", \"Engineer\"~\r\n\r\nglimpse(gps)\r\n\r\n\r\nRows: 685,169\r\nColumns: 4\r\n$ Timestamp <chr> \"1/6/2014 6:28\", \"1/6/2014 6:28\", \"1/6/2014 6:28\",~\r\n$ id        <dbl> 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35~\r\n$ lat       <dbl> 36.07623, 36.07622, 36.07621, 36.07622, 36.07621, ~\r\n$ long      <dbl> 24.87469, 24.87460, 24.87444, 24.87425, 24.87417, ~\r\n\r\nChanging of CarID and ID to categorical data.\r\n\r\n\r\ncar$CarID = as.factor(car$CarID)\r\ngps$id = as.factor(gps$id)\r\n\r\n\r\n\r\n2.6.1.4. Combining both first and last name.\r\nNext, we will combine both first and last name of the car datasets into one column for us to analyse the person easily. We will use the tidyr function unite to unify both the first and last name into name.\r\n\r\n\r\ncar_unite <- car %>%\r\n  unite(col = \"name\", LastName,FirstName, sep = \", \",  remove =FALSE) \r\n\r\n\r\n\r\n2.6.1.5. Change datatype of time and rename id to Carid\r\nNext, we will rename the id of gps to CarID to match with the car_unite data. Additionally, the Timestamp data of gps will be changed to the dttm format\r\n\r\n\r\ngps_cleaned <- rename(gps,CarID = id)\r\n\r\ngps_cleaned$Timestamp <- date_time_parse(gps_cleaned$Timestamp,\r\n                                 zone = \"\",\r\n                                 format = \"%m/%d/%Y %H:%M\")\r\n\r\n\r\n\r\nLastly, we will look at our cleaned dataset and we have done cleaning the data.\r\n\r\n\r\nglimpse(car_unite)\r\n\r\n\r\nRows: 44\r\nColumns: 6\r\n$ name                   <chr> \"Calixto, Nils\", \"Azada, Lars\", \"Bala~\r\n$ LastName               <chr> \"Calixto\", \"Azada\", \"Balas\", \"Barranc~\r\n$ FirstName              <chr> \"Nils\", \"Lars\", \"Felix\", \"Ingrid\", \"I~\r\n$ CarID                  <fct> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12~\r\n$ CurrentEmploymentType  <chr> \"Information Technology\", \"Engineerin~\r\n$ CurrentEmploymentTitle <chr> \"IT Helpdesk\", \"Engineer\", \"Engineer\"~\r\n\r\nglimpse(gps_cleaned)\r\n\r\n\r\nRows: 685,169\r\nColumns: 4\r\n$ Timestamp <dttm> 2014-01-06 06:28:00, 2014-01-06 06:28:00, 2014-01~\r\n$ CarID     <fct> 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35~\r\n$ lat       <dbl> 36.07623, 36.07622, 36.07621, 36.07622, 36.07621, ~\r\n$ long      <dbl> 24.87469, 24.87460, 24.87444, 24.87425, 24.87417, ~\r\n\r\n3. Methodology and Visualisation methods\r\nBelow we will discuss some methodology and visualization methods used to answer the questions later.\r\n3.1. Bar Chart\r\nFirst, we will be using a bar chart to analyse the number of patrons to each location. A bar chart is very useful to analyse categorical data based on number of instances.\r\nThe code uses both tidyverse and plotly packages to create the bar chart. First, a count was used to count each location by visits. Then a mutate function was used to create and sort the location by count in descending order. Next, a plotly bar chart was created by indicating the x and y axis with additional layout for the chart.\r\nThe plotly bar chart is accessible later in the question segment. \r\n3.2. Line chart\r\nTo visualize timeseries data, a time-series line chart is great for analysis.\r\nThe below line chart uses the top few most visited places to plot into a timeseries line. \r\n3.3. Geospatial visualization\r\nNext, a geospatial map visualisation is created to analyse the movement of each vehicle.\r\n\r\n3.4. Network analysis\r\nAn interactive network data analysis is created to visualise the realtionship between each person.\r\nNotice that the carid can be selected to see its relationship between other carid. Those that are nearest and highlighted are carid that have a close relationship with the person of interest.\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-07-28T13:03:03+08:00",
    "input_file": "visual-analytics-assignment-part-1.knit.md"
  }
]
